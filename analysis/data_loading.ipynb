{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "\n",
    "This script is needed to load the experiment data into the Sqlite database used. You can customize the input reports by modifying the `experiment_name` and `experiment_data_path` variables (by default, they will read from the output folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "from helpers.sqlite_helpers import pd_to_sqlDB, sql_query_to_pd, run_sql_query\n",
    "\n",
    "experiment_name = \"2025-05-30\"\n",
    "experiment_data_path = f\"../executions/{experiment_name}/output/reports\"\n",
    "\n",
    "TOOLS = ('jdime', 'spork', 'last_merge', 'mergiraf')\n",
    "TOOLS_TUPLES = [ ('jdime', 'last_merge'), ('spork', 'mergiraf'), ('last_merge', 'mergiraf') ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of initial tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from tool executions on scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tool in TOOLS:\n",
    "    logging.info(f\"Processing executions of {tool} tool\")\n",
    "    tool_executions_df = pd.read_csv(f'{experiment_data_path}/merge-tools/{tool}.csv', names=['project', 'merge_sha', 'file_path', 'output_file_path', 'result', 'time_in_ns'])\n",
    "    tool_executions_df['scenario_id'] = tool_executions_df['project'] + ':' + tool_executions_df['merge_sha']\n",
    "    pd_to_sqlDB(tool_executions_df, f\"{tool}_executions\")\n",
    "    logging.info(f\"Finished executions of {tool} tool\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equivalence Tool <-> Merge File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_files = {\n",
    "    'last_merge': 'merge_java-merge_last_merge_java.csv',\n",
    "    'spork': 'merge_spork_normalized_java-merge_spork_spork_normalized_java.csv',\n",
    "    'mergiraf': 'merge_java-merge_mergiraf_java.csv',\n",
    "    'jdime': 'merge_jdime_normalized_java-merge_jdime_java.csv'\n",
    "}\n",
    "\n",
    "for tool in TOOLS:\n",
    "    logging.info(f\"Processing equivalency between of {tool} tool\")\n",
    "    tool_equivalency_df = pd.read_csv(f'{experiment_data_path}/syntactic-comparison/{tools_files[tool]}', names=['project', 'merge_sha', 'file_path', 'file_a', 'file_b', 'outputs_equivalent'])\n",
    "    tool_equivalency_df['scenario_id'] = tool_equivalency_df['project'] + ':' + tool_equivalency_df['merge_sha']\n",
    "    pd_to_sqlDB(tool_equivalency_df, f\"{tool}_merge_equivalency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equivalence Tool A <-> Tool B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_files = {\n",
    "    'jdime_last_merge': 'merge_jdime_java-merge_last_merge_jdime_normalized_java.csv',\n",
    "    'spork_mergiraf': 'merge_mergiraf_spork_normalized_java-merge_spork_spork_normalized_java.csv',\n",
    "    'last_merge_mergiraf': 'merge_mergiraf_format_normalized_java-merge_last_merge_format_normalized_java.csv'\n",
    "}\n",
    "\n",
    "for (tools, equivalency_file_name) in tools_files.items():\n",
    "    tools_equivalency_df = pd.read_csv(f'{experiment_data_path}/syntactic-comparison/{equivalency_file_name}', names=['project', 'merge_sha', 'file_path', 'file_a', 'file_b', 'outputs_equivalent'])\n",
    "    tools_equivalency_df['scenario_id'] = tools_equivalency_df['project'] + ':' + tools_equivalency_df['merge_sha']\n",
    "    pd_to_sqlDB(tools_equivalency_df, f\"{tools}_equivalency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equivalence between conflicts Tool A <-> Tool B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_files = {\n",
    "    'jdime_last_merge': \"merge_jdime_java-merge_last_merge_java.csv\",\n",
    "    'spork_mergiraf': \"merge_mergiraf_java-merge_spork_java.csv\",\n",
    "    'last_merge_mergiraf': \"merge_mergiraf_java-merge_last_merge_java.csv\",\n",
    "}\n",
    "\n",
    "for (toolA, toolB) in TOOLS_TUPLES:\n",
    "    tool_a_tool_b_file_name = tools_files[f\"{toolA}_{toolB}\"]\n",
    "    tool_a_tool_b_conflicts_df = pd.read_csv(f'{experiment_data_path}/conflicts-comparison/{tool_a_tool_b_file_name}', names=['project', 'merge_sha', 'file_path', 'file_a_conflict', 'file_b_conflict', 'outputs_equivalent'])\n",
    "    tool_a_tool_b_conflicts_df['scenario_id'] = tool_a_tool_b_conflicts_df['project'] + ':' + tool_a_tool_b_conflicts_df['merge_sha']\n",
    "    pd_to_sqlDB(tool_a_tool_b_conflicts_df, f\"{toolA}_{toolB}_conflicts\")\n",
    "    run_sql_query(f\"\"\"CREATE INDEX IF NOT EXISTS idx_file_{toolA}_{toolB}_conflicts ON {toolA}_{toolB}_conflicts (file_path, file_a_conflict, file_b_conflict, outputs_equivalent)\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global executions informations by file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sql_query(f\"\"\"DROP VIEW IF EXISTS global_executions\"\"\")\n",
    "run_sql_query(f\"\"\"\n",
    "  CREATE VIEW global_executions AS SELECT\n",
    "    spork_executions.scenario_id,\n",
    "    spork_executions.project,\n",
    "    spork_executions.merge_sha,\n",
    "    spork_executions.file_path,\n",
    "    spork_executions.result as spork_result,\n",
    "    mergiraf_executions.result as mergiraf_result,\n",
    "    jdime_executions.result as jdime_result,\n",
    "    last_merge_executions.result as last_merge_result\n",
    "  FROM\n",
    "    spork_executions\n",
    "  JOIN\n",
    "    last_merge_executions\n",
    "  ON\n",
    "    spork_executions.scenario_id = last_merge_executions.scenario_id AND spork_executions.file_path = last_merge_executions.file_path\n",
    "  JOIN\n",
    "    mergiraf_executions\n",
    "  ON\n",
    "    spork_executions.scenario_id = mergiraf_executions.scenario_id AND spork_executions.file_path = mergiraf_executions.file_path\n",
    "  JOIN\n",
    "    jdime_executions\n",
    "  ON\n",
    "    spork_executions.scenario_id = jdime_executions.scenario_id AND spork_executions.file_path = jdime_executions.file_path\n",
    "\"\"\")\n",
    "\n",
    "sql_query_to_pd(f\"\"\"SELECT * FROM global_executions\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information about execution per scenery on each tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_executions_per_commit_query(tool_name: str) -> str:\n",
    "    return f\"\"\"\n",
    "        SELECT\n",
    "            e.scenario_id,\n",
    "            e.project,\n",
    "            e.merge_sha,\n",
    "            SUM(time_in_ns) as time_in_ns,\n",
    "            CASE \n",
    "                WHEN SUM(result = \"TOOL_ERROR\") > 0 THEN \"TOOL_ERROR\"\n",
    "                WHEN SUM(result = \"SUCCESS_WITH_CONFLICTS\") > 0 THEN \"SUCCESS_WITH_CONFLICTS\"\n",
    "                ELSE \"SUCCESS_WITHOUT_CONFLICTS\"\n",
    "            END AS result,\n",
    "            CASE WHEN SUM(outputs_equivalent) == COUNT(me.file_path) THEN 1 ELSE 0 END AS outputs_equivalent\n",
    "        FROM\n",
    "            {tool_name}_executions e\n",
    "        JOIN\n",
    "            {tool_name}_merge_equivalency me\n",
    "        ON\n",
    "            e.file_path = me.file_path\n",
    "        GROUP BY\n",
    "            e.scenario_id\n",
    "    \"\"\"\n",
    "\n",
    "for tool in TOOLS:\n",
    "    logging.info(f\"Creating view {tool}_executions_per_commit\")\n",
    "    run_sql_query(f\"\"\"DROP VIEW IF EXISTS {tool}_executions_per_commit\"\"\")\n",
    "    run_sql_query(f\"\"\"CREATE VIEW {tool}_executions_per_commit AS {get_executions_per_commit_query(tool)}\"\"\")\n",
    "\n",
    "query = ' UNION '.join([f\"SELECT scenario_id, time_in_ns, result, outputs_equivalent, '{tool}' as tool FROM {tool}_executions_per_commit\" for tool in TOOLS])\n",
    "sql_query_to_pd(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information about execution per scenery on each tool (excluding failures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_executions_per_commit_query(tool_name: str) -> str:\n",
    "    return f\"\"\"\n",
    "        SELECT\n",
    "            *\n",
    "        FROM\n",
    "            {tool}_executions_per_commit\n",
    "        WHERE\n",
    "            result <> 'TOOL_ERROR'\n",
    "    \"\"\"\n",
    "\n",
    "for tool in TOOLS:\n",
    "    logging.info(f\"Creating view {tool}_executions_per_commit_filtered\")\n",
    "    run_sql_query(f\"\"\"DROP VIEW IF EXISTS {tool}_executions_per_commit_filtered\"\"\")\n",
    "    run_sql_query(f\"\"\"CREATE VIEW {tool}_executions_per_commit_filtered AS {get_filtered_executions_per_commit_query(tool)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global information about execution in each scenery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sql_query(f\"\"\"DROP VIEW IF EXISTS global_executions_per_commit\"\"\")\n",
    "run_sql_query(f\"\"\"CREATE VIEW global_executions_per_commit AS SELECT\n",
    "    spork.scenario_id,\n",
    "    spork.project,\n",
    "    spork.merge_sha,\n",
    "    last_merge.result as last_merge_result,\n",
    "    jdime.result as jdime_result,\n",
    "    spork.result as spork_result,\n",
    "    mergiraf.result as mergiraf_result\n",
    "  FROM\n",
    "    spork_executions_per_commit spork\n",
    "  JOIN\n",
    "    last_merge_executions_per_commit last_merge\n",
    "  ON\n",
    "    spork.scenario_id = last_merge.scenario_id\n",
    "  JOIN\n",
    "    mergiraf_executions_per_commit mergiraf\n",
    "  ON\n",
    "    spork.scenario_id = mergiraf.scenario_id\n",
    "  JOIN\n",
    "    jdime_executions_per_commit jdime\n",
    "  ON\n",
    "    spork.scenario_id = jdime.scenario_id\n",
    "\"\"\")\n",
    "sql_query_to_pd(f\"\"\"select * from global_executions_per_commit\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global information about execution in each scenery (excluding failures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sql_query(f\"\"\"DROP VIEW IF EXISTS global_executions_per_commit_filtered\"\"\")\n",
    "run_sql_query(f\"\"\"CREATE VIEW global_executions_per_commit_filtered AS SELECT\n",
    "    spork.scenario_id,\n",
    "    spork.project,\n",
    "    spork.merge_sha,\n",
    "    spork.result as spork_result,\n",
    "    last_merge.result as last_merge_result,\n",
    "    mergiraf.result as mergiraf_result,\n",
    "    jdime.result as jdime_result\n",
    "  FROM\n",
    "    spork_executions_per_commit_filtered spork\n",
    "  JOIN\n",
    "    last_merge_executions_per_commit_filtered last_merge\n",
    "  ON\n",
    "    spork.scenario_id = last_merge.scenario_id\n",
    "  JOIN\n",
    "    mergiraf_executions_per_commit_filtered mergiraf\n",
    "  ON\n",
    "    spork.scenario_id = mergiraf.scenario_id\n",
    "  JOIN\n",
    "    jdime_executions_per_commit_filtered jdime\n",
    "  ON\n",
    "    spork.scenario_id = jdime.scenario_id\n",
    "\"\"\")\n",
    "sql_query_to_pd(f\"\"\"select * from global_executions_per_commit_filtered\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntactic equivalence between tools per scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_equivalency_per_tool(toolA: str, toolB: str) -> str:\n",
    "    return f\"\"\"\n",
    "        SELECT\n",
    "            scenario_id,\n",
    "            project,\n",
    "            merge_sha,\n",
    "            CASE\n",
    "                WHEN SUM(CASE WHEN outputs_equivalent = 1 THEN 1 ELSE 0 END) = COUNT(outputs_equivalent) THEN 1\n",
    "                ELSE 0\n",
    "            END as outputs_equivalent\n",
    "        FROM\n",
    "            {toolA}_{toolB}_equivalency\n",
    "        GROUP BY\n",
    "            scenario_id\n",
    "    \"\"\"\n",
    "\n",
    "for (toolA, toolB) in TOOLS_TUPLES:\n",
    "    run_sql_query(f\"\"\"DROP VIEW IF EXISTS {toolA}_{toolB}_equivalency_per_commit\"\"\")\n",
    "    run_sql_query(f\"\"\"CREATE VIEW {toolA}_{toolB}_equivalency_per_commit AS {get_output_equivalency_per_tool(toolA, toolB)}\"\"\")\n",
    "    display(sql_query_to_pd(f\"\"\"select * from {toolA}_{toolB}_equivalency_per_commit\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison between conflicts Tool A <-> Tool B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (tool_a, tool_b) in TOOLS_TUPLES:\n",
    "  files_in_which_both_tools_found_conflict_and_they_are_equal_query = f\"\"\"\n",
    "    SELECT\n",
    "      DISTINCT scenario_id, file_path, 1 as all_conflicts_match\n",
    "    FROM\n",
    "      {tool_a}_{tool_b}_conflicts c1\n",
    "    WHERE\n",
    "      NOT EXISTS (\n",
    "          SELECT 1\n",
    "          FROM {tool_a}_{tool_b}_conflicts c2\n",
    "          WHERE c1.file_path = c2.file_path\n",
    "          AND c1.file_a_conflict = c2.file_a_conflict\n",
    "          AND c1.file_b_conflict = c2.file_b_conflict\n",
    "          AND c2.outputs_equivalent = 0\n",
    "      )\n",
    "  \"\"\"\n",
    "\n",
    "  files_in_which_both_tools_found_conflict_and_they_are_equal = sql_query_to_pd(files_in_which_both_tools_found_conflict_and_they_are_equal_query)\n",
    "  file_paths_in_which_both_tools_found_conflict_and_they_are_equal = \"', '\".join(files_in_which_both_tools_found_conflict_and_they_are_equal['file_path'].tolist())\n",
    "\n",
    "  files_in_which_both_tools_found_conflict_but_they_are_different_query = f\"\"\"\n",
    "    SELECT\n",
    "      scenario_id, file_path, 0 as all_conflicts_match\n",
    "    FROM\n",
    "      {tool_a}_{tool_b}_conflicts c1\n",
    "    WHERE\n",
    "      file_path NOT IN ('{file_paths_in_which_both_tools_found_conflict_and_they_are_equal}')\n",
    "    GROUP BY\n",
    "      file_path\n",
    "  \"\"\"\n",
    "\n",
    "  tool_a_tool_b_global_conflicts_information_query = f\"\"\"\n",
    "    SELECT\n",
    "      scenario_id, file_path, 1 as all_conflicts_match\n",
    "    FROM\n",
    "      {tool_a}_{tool_b}_conflicts c1\n",
    "    WHERE\n",
    "      file_path IN ('{file_paths_in_which_both_tools_found_conflict_and_they_are_equal}')\n",
    "    GROUP BY\n",
    "      file_path\n",
    "    UNION\n",
    "    {files_in_which_both_tools_found_conflict_but_they_are_different_query}\n",
    "  \"\"\"\n",
    "\n",
    "  tool_a_tool_b_global_conflicts_information_df = sql_query_to_pd(tool_a_tool_b_global_conflicts_information_query)\n",
    "  pd_to_sqlDB(tool_a_tool_b_global_conflicts_information_df, f\"{tool_a}_{tool_b}_global_conflicts_information\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commits_df = pd.read_csv(f'{experiment_data_path}/commits.csv', names=['project', 'merge', 'right', 'left'])\n",
    "commits_df['scenario_id'] = commits_df['project'] + ':' + commits_df['merge']\n",
    "pd_to_sqlDB(commits_df, \"commits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_df = pd.read_csv(f'{experiment_data_path}/projects.csv', names=['path', 'name'])\n",
    "pd_to_sqlDB(projects_df, \"projects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving data from GitHub Api of scenarios that require build and test execution\n",
    "\n",
    "In these scenarios, tool A reports a conflict and tool B does not, however, B is not equivalent to the merge commit. In this case, we need to perform the analysis using the result of the test suite execution on B.\n",
    "\n",
    "For running these scripts, we need to recover data regarding test executions with the GitHub API. For that, we need to provide a GitHub PAT --- you can reuse the same token used to execute the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyGithub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GITHUB_TOKEN = ''\n",
    "ANALYSIS_GITHUB_REPO_OWNER = 'jpedroh'\n",
    "ANALYSIS_GITHUB_REPO_NAME = 'mining-framework-analysis'\n",
    "WORKFLOW_ID = 'mining_framework.yaml'\n",
    "\n",
    "from github import Github\n",
    "from github import Auth\n",
    "\n",
    "auth = Auth.Token(GITHUB_TOKEN)\n",
    "g = Github(auth=auth)\n",
    "\n",
    "def get_results_for_tool(tool: str, scenarios: pd.DataFrame):\n",
    "    repository = g.get_repo(f\"{ANALYSIS_GITHUB_REPO_OWNER}/{ANALYSIS_GITHUB_REPO_NAME}\")\n",
    "    result = []\n",
    "\n",
    "    for scenario in scenarios.itertuples(index=False):\n",
    "        project = scenario[1]\n",
    "        merge_sha = scenario[2]\n",
    "        branch = f\"mining-framework-analysis_{project}_{merge_sha}_merge.{tool}.java\"\n",
    "\n",
    "        workflow = repository.get_workflow(WORKFLOW_ID)\n",
    "        latest_workflow_run = workflow.get_runs(branch=branch, status='completed').get_page(0)[0]\n",
    "\n",
    "        latest_workflow_jobs = latest_workflow_run.jobs().get_page(0)\n",
    "        at_least_one_job_passes = any(job.conclusion == 'success' for job in latest_workflow_jobs)\n",
    "\n",
    "        result.append({\n",
    "            'scenario_id': scenario.scenario_id,\n",
    "            'tool': tool,\n",
    "            'status': 'success' if at_least_one_job_passes else 'failure'\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(result)\n",
    "        \n",
    "scenarios = sql_query_to_pd(f\"\"\"SELECT scenario_id, project, merge_sha FROM global_executions_per_commit_filtered\"\"\")\n",
    "\n",
    "last_merge_results_df = get_results_for_tool('last_merge', scenarios)\n",
    "jdime_results_df = get_results_for_tool('jdime', scenarios)\n",
    "\n",
    "mergiraf_results_df = get_results_for_tool('mergiraf', scenarios)\n",
    "spork_results_df = get_results_for_tool('spork', scenarios)\n",
    "\n",
    "concatenated_results_df = pd.concat([last_merge_results_df, jdime_results_df, mergiraf_results_df, spork_results_df], ignore_index=True)\n",
    "pd_to_sqlDB(concatenated_results_df, \"test_results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
